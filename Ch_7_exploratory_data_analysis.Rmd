---
title: "Ch_7_exploratory_data_analysis.Rmd"
author: "Samir Gadkari"
date: "1/12/2021"
output: html_document
---

Hadley Wickham's [R for data science](https://r4ds.had.co.nz/exploratory-data-analysis.html), Chapter 7 problems and notes
```{r Load libraries}
library(tidyverse)
library(ggstance)
library(lvplot)
library(ggbeeswarm)
library(modelr)
# library(seriation)
```

Since this is a large dataset, only a few rows are printed when you type
flights in the console. To see all the rows, type View(flights) in the console.
We're going to explore our data through:
  * variations within the variables
  * covariations between variables

## Variation

You can use bar plots to find variations in categorical variables:
```{r}
# Variation as a plot:
diamonds %>%
  ggplot(aes(x = cut)) +
  geom_bar()

# Variation as a table:
diamonds %>%
  count(cut) %>%           # counts the number of each type
  mutate(prop = n/sum(n))  # gives the proportion of each type
```

You can use histograms to find variations in continuous data:
```{r}
diamonds %>%
  ggplot(aes(x = carat)) +
  geom_histogram(binwidth = 0.5) # You should explore data with different binwidths

diamonds %>%
  count(cut_width(carat, 
                  0.5)) %>%  # width is required for cut_width
  mutate(prop = n / sum(n))
```

To overlay multiple histograms, use geom_freqpoly(). It uses a different
colored line for each histogram, and so is easier to understand.
```{r}
ggplot(data = diamonds, mapping = aes(x = carat, color = cut)) +
  geom_freqpoly(binwidth = 0.1)
```

### Typical values

  * Which values are the most common? Why?
  * Which values are rare? Why? Does that match your expectations?
  * Can you see any unusual patterns? What might explain them?
Let's see an example that answers some of these questions:

#### Example
```{r}
smaller <- diamonds %>%
  filter(carat < 3)

smaller %>%
  ggplot(aes(x = carat)) +
  geom_histogram(binwidth = 0.01)
```

Some of the questions from this plot could be:
  * Why are there more diamonds at whole carats and common fractions of carats?
    - More people buy diamonds at whole carat points or fractions of
    carat points. Instead of telling your wife, I bought a 0.3875 carat
    diamond, it will help to say I bought a 1/3 carat diamond. The price
    will be lower for the 1/3 carat, but it's also easier to remember.
  * Why are there more diamonds slightly to the right of each peak than there are slightly to the left of each peak?
    - Everyone wants a diamond at or slightly above the whole carat level,
    so they can say the carat level of the diamond. If the diamond is
    smaller, it may be cut to create two smaller diamonds.
  * Why are there no diamonds bigger than 3 carats?
    - This may be just natural. More smaller carat diamonds occur in
    nature than larger carat diamonds. Not sure if this is physics
    related? Something to check. It's always good to get to the
    first principles.

Clusters of similar values suggest that subgroups exist in your data. To understand the subgroups, ask:

  * How are the observations within each cluster similar to each other?
    - Similar because each cluster has the same shape. There are many
    more diamonds at whole carat levels, then their number drops of
    until there is a small surge at the fractional carat level, and
    then it drops off until the next whole carat level.
  * How are the observations in separate clusters different from each other?
    - You notice that as the whole carat value increases, the number of
    diamonds decreases. The whole group has a similar shape but the
    shape is smaller
  * How can you explain or describe the clusters?
    - There are many more diamonds at whole carat levels,
    then their number drops of until there is a small surge
    at the fractional carat level, and then it drops off until
    the next whole carat level.
  * Why might the appearance of clusters be misleading?
    - You have to make sure this is not a result of the binwidth
    parameter. That is why, you should try different binwidths to
    see if the same patterns occur.
    
### Unusual values
Outliers are observations that are unusual; data points that don’t seem to
fit the pattern. Outliers could occur:
  * due to data entry errors
  * are really valid data that occurs less often

The evidence of outliers in a histogram is the wide limits on the x-axis:
```{r}
ggplot(data = diamonds, 
       mapping = aes(x = y)) +  # y is the width of the diamond
  geom_histogram(binwidth = 0.5)

ggplot(data = diamonds, 
       mapping = aes(x = y)) +  # y is the width of the diamond
  geom_histogram(binwidth = 0.5) +
  coord_cartesian(ylim = c(0, 50)) # ylim selects the y-axis range
# You can also select the x-axis range using xlim.
# ggplot2's xlim, ylim throw away data beyond the limits.
```
Now we can extract those outliers using dplyr:
```{r}
(unusual <- diamonds %>%
  filter(y < 3 | y > 20) %>%
  select(price, x, y, z) %>%
  arrange(y))
```
The y width is measured in mm. Since it cannot be 0, these values
are incorrect. The other 32mm and 59mm diamonds are more than an
inch long, yet their price is not exorbitant. They must have
incorrect values as well.

If your analysis with and without outliers is the same,
you should remove those outliers and disclose it in your writeup.
If not, you must justify where those outlier values came from.

### 7.3.4 Exercises

1. Explore the distribution of each of the x, y, and z variables in diamonds. What do you learn? Think about a diamond and how you might decide which dimension is the length, width, and depth.
```{r}
hist <- function(df, v, v_label, binwidth, y_lim_min = NULL, y_lim_max = NULL) {
  tmp_plot <- ggplot(data = df, mapping = aes(x = v)) +
      geom_histogram(binwidth = binwidth) +
      labs(x = v_label)

  if(!is.null(y_lim_min) & !is.null(y_lim_max)) {
    tmp_plot <- tmp_plot +
      coord_cartesian(ylim = c(y_lim_min, y_lim_max))
  }
  
  (tmp_plot)
}

hist(diamonds, diamonds$x, 'x', 0.5)
hist(diamonds, diamonds$y, 'y', 0.5)
hist(diamonds, diamonds$z, 'z', 0.5)
```
Looks like x has outliers below 3.5 and above 10,
y has outliers below 3 and above 20,
z has outliers below 2 and above 10.
```{r}
hist(diamonds, diamonds$x, 'x', 0.5, 0, 50)
hist(diamonds, diamonds$y, 'y', 0.5, 0, 50)
hist(diamonds, diamonds$z, 'z', 0.5, 0, 50)
```
We can see the large number of x = 0, z = 0 and z > 30 values.
We can find the x = 0, and z = 0 values using the same procedure above:
```{r}
diamonds %>%
  filter(x == 0 | y == 0 | z == 0 | z > 30) %>%
  select(price, x, y, z, clarity, cut)
```
The diamonds with the x, y, and z values of 0 are errors.

The z 31.8 diamond is priced at 1970 for a 5mm x 5mm diamond with a height
of almost 32mm (25.4mm = 1 inch). It's cut is very good, and clarity is
middle-level. Is the price of $1970 small for such a diamond? Let's look at other 5mm x 5mm diamonds to compare:
```{r}
diamonds %>%
  filter(x > 4.9 & x < 5.1 & y > 4.9 & y < 5.1 & clarity == 'VS1' & cut == 'Very Good') %>%
  select(price, x, y) %>%
  ggplot(aes(x = price)) +
  geom_histogram()
```

So a diamond with the $1970 price and a z of 31.8 is valid (since there
are other diamonds without the large z value but the same price).

2. Explore the distribution of price. Do you discover anything unusual or surprising? (Hint: Carefully think about the binwidth and make sure you try a wide range of values.)
```{r}
hist(diamonds, diamonds$price, 'price', 50)
hist(diamonds, diamonds$price, 'price', 100)
hist(diamonds, diamonds$price, 'price', 150)
hist(diamonds, diamonds$price, 'price', 250)
hist(diamonds, diamonds$price, 'price', 500)
hist(diamonds, diamonds$price, 'price', 750)
hist(diamonds, diamonds$price, 'price', 1000)
hist(diamonds, diamonds$price, 'price', 1250)
hist(diamonds, diamonds$price, 'price', 1500)
hist(diamonds, diamonds$price, 'price', 1750)
hist(diamonds, diamonds$price, 'price', 2000)
```
There are no diamonds under $500. There is a steep rise from
$500 through around $800. Most of the diamonds are around $800.
Then there is a steep fall until around $4000. There is a small
bump (which means more diamonds are available) around $4500.
This is visible even if we raise the binwidth for the histogram
from 50 through 500.
If this is due to market forces, maybe there are two sets of
people (one set can afford diamonds < $1000, and another can afford
diamonds < $5000)?

3. How many diamonds are 0.99 carat? How many are 1 carat? What do you think is the cause of the difference?
```{r}
diamonds %>%
  filter(carat == 0.99 | carat == 1.0) %>%
  summarise(
    almost_a_carat = sum(carat == 0.99),
    full_one_carat = sum(carat == 1.0)
  )
```
The reason is nobody wants to say they have a diamond that is
almost a carat. Instead they want to say they have a diamond
that is 1 carat. If there are many diamonds that are almost a carat,
they may be sold for industrial purposes. There are now only
23 unsold "almost-a-carat" diamonds.

4. Compare and contrast coord_cartesian() vs xlim() or ylim() when zooming in on a histogram. What happens if you leave binwidth unset? What happens if you try and zoom so only half a bar shows?

According to the help system on coord_cartesian:
  * setting xlim, ylim on coord_cartesian will zoom the plot
  * setting xlim(), ylim() on the scales will discard data
    that is not within those limits before drawing the plot
Let's see this in action:
```{r}
diamonds %>%
  ggplot(aes(x = price)) +
  geom_histogram(binwidth = 250) +
  coord_cartesian(xlim = c(3500, 5500))
```
You can see how the height of the plot above is large. This is because
we're just zoomed into a price range where the counts are low.
The rest of the plot with high counts is still there - it's just not seen.

```{r}
hist(diamonds, diamonds$price, 'price', 500)
diamonds %>%
  ggplot(aes(x = price)) +
  geom_histogram(binwidth = 250, na.rm = TRUE) +
  xlim(c(3500, 5500))
```
The warnings show us that values were removed.

If you leave binwidth unset for a histogram, you get a default of 30
bins and a warning asking you to look into the correct bin width.
```{r}
diamonds %>%
  ggplot(aes(x = price)) +
  geom_histogram(binwidth = 250, na.rm = TRUE) +
  xlim(c(5001, 5500))

diamonds %>%
  ggplot(aes(x = price)) +
  geom_histogram(binwidth = 250, na.rm = TRUE) +
  xlim(c(5200, 5500))
```
This shows that when you try to zoom to a width less than the bar width,
you will not get even half a bar on the screen

## Missing values
1. Either drop the entire row that has any missing values:
```{r}
diamonds %>%
  filter(between(y, 3, 20))
```
This option is not reccommended because:
  * even if one variable value is invalid, other column values
    may be valid
  * If your dataset has lots of missing values, you won't have
    many rows left after this approach
2. Replace the unusual values with different values
```{r}
diamonds %>%
  mutate(y = ifelse(y < 3 | y > 20, NA, y))
```
3. If you want to compare cases with missing values against cases
with values:
```{r}
nycflights13::flights %>%
  mutate(
    cancelled = is.na(dep_time),  # TRUE/FALSE based on dep_time
    sched_hour = sched_dep_time %/% 100, # sched_dep_time has no NAs
    sched_min = sched_dep_time %% 100,
    sched_dep_time = sched_hour + sched_min / 60 # new sched_dep_time
  ) %>%
  ggplot(mapping = aes(sched_dep_time)) +  # we're plotting sched_dep_time
  geom_freqpoly(mapping = aes(color = cancelled), # cancelled or not
                binwidth = 1/4)
```
This plot isn't great, since there are many more noncancelled flights
compared to cancelled flights.
### case_when
Alternatively, you can use case_when(). It
  * allows you to vectorize multiple if_else() statements
  * example:
```{r}
x <- 1:50
case_when(
  x %% 35 == 0 ~ "fizz_buzz",
  x %% 7 == 0 ~ "fizz",
  x %% 5 == 0 ~ "buzz",
  TRUE ~ as.character(x)
)
```
Like an if statement, the arguments are evaluated in order, and
they proceed from the most specific to the most general.
If none of the cases match, result is NA.
The RHS must be of the same type for each case.
The sequence of operation of case_when is:
  * evaluate all RHS values for the given input. This is done even if
    the LHS does not match the value for this case. This may cause
    NAs to be produced within the calculations, even though there are no
    NAs seen in the output.
  * evaluate the LHS values
  * construct the result by mapping the correct RHS to the LHS values.
Another example:
```{r}
(y <- seq(-2, 2, by = 0.5))
case_when(
  y >= 0 ~ sqrt(y),
  TRUE ~ y
)
```
Another example:
```{r}
starwars %>%
  select(name:mass, gender, species) %>%
  mutate(
    type = case_when(
      height > 200 | mass > 200 ~ "large", # can have complex LHS
      species == "Droid" ~ "robot",
      TRUE ~ "other"
    )
  ) %>%
  select(name, type)
```

R and ggplot2 subscribe to "missing values should never silently go 
missing." You always get a warning. Use na.rm = TRUE to remove 
missing values so you don't get the warning.

### 7.4.1 Exercises

1. What happens to missing values in a histogram? What happens to missing values in a bar chart? Why is there a difference?

Missing values in a histogram are removed before plotting.
A warning shows how many values were removed by ggplot.

Let's see how missing values are handled in a bar chart:
```{r}
nycflights13::flights %>%
  select(carrier) %>%
  ggplot() +
  geom_bar(mapping = aes(carrier))
```
There are no messages about missing values when summing counts for a bar
chart. Missing values are silently thrown away.
Why is there a difference? I have not found an answer for that yet.

2. What does na.rm = TRUE do in mean() and sum()?
If na.rm is TRUE, functions like mean and sum remove NA values from
the data before starting their computations.

## Covariation
Variation shows how the data within a variable varies.
Covariation shows if the data in two or more variables varies together
in a similar way (either +ve covariation or -ve covariation).

Very often we want to see the distribution of a numerical variable against
multiple values of a categorical variable.
geom_freqpoly is not a very good way to see this.
If one group has lower counts than the rest, we can't see it very well since the scaling is done by the higher values.

```{r}
ggplot(data = diamonds, mapping = aes(x = price)) +
  geom_freqpoly(mapping = aes(color = cut), binwidth = 500)
```
Instead, we plot the density i.e. we standardise the plot such that
the area under each polygon is 1.
```{r}
ggplot(data = diamonds, mapping = aes(x = price, y = ..density..)) +
  geom_freqpoly(mapping = aes(color = cut), binwidth = 500)
```
It seems like fair diamonds (lowest quality) have the highest average 
price. Maybe we're not interpreting this right.

Let's see this in a boxplot:
```{r}
ggplot(data = diamonds, mapping = aes(x = cut, y = price)) +
  geom_boxplot()
```
It supports the counter-intuitive argument that better quality diamonds
are cheaper (on average).

cut is an ordered factor (Good is better than Fair, etc.).
If you have to re-order the categorical variable, use reorder().
reorder(categorical, numerical, function) applies the function on the
numerical values to reorder the categorical variable.
```{r}
ggplot(data = mpg, 
       mapping = aes(x = reorder(class, hwy, FUN = median), 
                     y = hwy)) +
  geom_boxplot() +
  coord_flip()  # flip the graph 90 degrees. This helps with long names.
```

### 7.5.11 Exercises

1. Use what you’ve learned to improve the visualisation of the departure times of cancelled vs. non-cancelled flights.
```{r}
nycflights13::flights %>%
  mutate(
    cancelled = is.na(dep_time),
    sched_hour = sched_dep_time %/% 100,
    sched_min = sched_dep_time %% 100,
    sched_dep_time = sched_hour + sched_min / 60
  ) %>%
  ggplot(mapping = aes(x = sched_dep_time, y = ..density..)) +
  geom_freqpoly(mapping = aes(color = cancelled), binwidth = 1)
```

The fraction of cancelled flights increases from 5am through 8pm.
Then it decreases. The fraction of non-cancelled flights increases
from 5am through 8am, goes down a little, and starts going up
again around 2pm through 8pm. It decreases after that.
The main point this plot shows is there are two humps - one around
8pm and one around 3pm for fraction of flights.
Cancelled flights increase rapidly from 5am, stay steady until 2pm,
then increase rapidly and stay high until 8pm.
Since more flights means more people travel at that time,
we can see that most people want to travel from 5am through 2pm
(presumably so they can have meetings till the end of the day),
and from 2pm through 8pm (coming back home).
```{r}
flights <- nycflights13::flights %>%
  mutate(
    cancelled = is.na(dep_time),
    sched_hour = sched_dep_time %/% 100,
    sched_min = sched_dep_time %% 100,
    sched_dep_time = as.factor(round(sched_hour + sched_min / 60, 0))
  ) %>%
  subset(select = -c(sched_hour, sched_min))

flights %>%
  ggplot() +
  geom_bar(mapping = aes(x = sched_dep_time,
                             fill = cancelled), 
           position = 'dodge')
```
The number of cancelled flights is constant until 3pm at which time
it jumps up and stays high until after 8pm.
You can also see the two humps for non-cancelled flights around 8am
and 4pm.

2. What variable in the diamonds dataset is most important for predicting the price of a diamond? How is that variable correlated with cut? Why does the combination of those two relationships lead to lower quality diamonds being more expensive?

```{r}
pairs(diamonds)
```
Looking at the price row in the above plot, the line goes up for carat,
x, y, and z. Let's plot these separately against price to see what is
the best correlation. Also note that the pairs function converts
categorical data to numerical data automatically without knowing
for ex. which cut is better than the other. We have to reorder each
categorical plots with the right sequence to see if any categorical
variables have better correlation with the price. Let's do the 
carat, and x, y, z first, and let's plot them on the same xlim.
```{r}
plot_numeric_corr <- function(data, var_x, name_x, var_y, name_y) {
  data %>%
    ggplot(mapping = aes(x = var_x, y = var_y)) +
    geom_point(alpha = 1/10) +
    xlab(name_x) +
    ylab(name_y) +
    coord_cartesian(xlim = c(0, 10))
}

plot_numeric_corr(diamonds, 
                  diamonds$carat, 'carat', 
                  diamonds$price, 'price')
plot_numeric_corr(diamonds, 
                  diamonds$x, 'x', 
                  diamonds$price, 'price')
plot_numeric_corr(diamonds, 
                  diamonds$y, 'y', 
                  diamonds$price, 'price')
plot_numeric_corr(diamonds, 
                  diamonds$z, 'z', 
                  diamonds$price, 'price')
```
Looking at the x-axis range, we can see that for x and y the range
over which most of the points go up are larger than the range for z
and carats. In fact, the range for carat is the smallest, so it is
the most important in determining the price.

We have worked with cut earlier, and found it is not very important
to price. We have not looked at color and clarity, which we will
do now:
```{r}
diamonds %>%
  ggplot(mapping = aes(x = color, y = price)) +
  geom_boxplot()
```
We see that the prices go up with color. The worst color is D, and
the best is J. They do not go up as fast as with carat, though.
```{r}
diamonds %>%
  ggplot(mapping = aes(x = clarity, y = price)) +
  geom_boxplot()
```
Here, the price goes lower as the clarity increases, which is strange.
Maybe the diamonds found with lower clarity are of a higher carat,
thus their price is high.

Let's see how carat and cut are correlated:
```{r}
ggplot(data = diamonds, mapping = aes(x = cut, y = carat)) +
  geom_boxplot()
```

The highest correlation of the price is against the carat.
Even though the cut is just Fair, diamonds found with this cut are
of a higher carat. This causes those diamonds to be values higher.
The diamonds of an Ideal cut are of a smaller carat, thus their
prices are lower.

3. Install the ggstance package, and create a horizontal boxplot. How does this compare to using coord_flip()?

```{r}
diamonds %>%
  ggplot(mapping = aes(price, cut)) +
  geom_boxploth()
```
```{r}
diamonds %>%
  ggplot(mapping = aes(x = cut, y = price)) +
  geom_boxplot() +
  coord_flip()
```
The output of both ggstance::geom_boxploth and ggplot2::geom_boxplot + 
coord_flip are the same. When creating with ggstance, we give the
x and y values as in the final plot. With ggplot2, we give the x and y
values as in the vertical plot, and let coord_flip flip them around.

3. One problem with boxplots is that they were developed in an era of much smaller datasets and tend to display a prohibitively large number of “outlying values”. One approach to remedy this problem is the letter value plot. Install the lvplot package, and try using geom_lv() to display the distribution of price vs cut. What do you learn? How do you interpret the plots?

The lvplot was created because there could be many "outliers" beyond
the edges of the box in a boxplot. For a boxplot, outside the
IQR it was not possible to interpret how far off the points were.

Now, with the lvplot, you can give a k value. By default k = 3, and
you get the thicker boxplot type box with the median line and the IQR,
but you also get another thinner inner box. The inner box shows how long
the octiles are. This way you can interpret more of the data.

```{r}
p <- ggplot(data = diamonds, mapping = aes(cut, price))
p + geom_lv()
p + geom_lv(aes(fill = ..LV..))
```

5. Compare and contrast geom_violin() with a facetted geom_histogram(), or a coloured geom_freqpoly(). What are the pros and cons of each method?

geom_violin is a mirrored density plot (a combination of boxplot and
density). It shows you the distribution of each grouped categorical
value against a numerical value.

geom_histogram shows you a binned numerical variable against a count
of the instances in that bin.

geom_freqpoly shows you a polygon for each category of a categorical
variable against the count in that bin.
If you use ..density.. on the y axis, it will show you the density
of the distribution. This means the area under each polygon is 1.

```{r}
p <- ggplot(data = diamonds, mapping = aes(cut, price))
p + geom_violin()
```

6. If you have a small dataset, it’s sometimes useful to use geom_jitter() to see the relationship between a continuous and categorical variable. The ggbeeswarm package provides a number of methods similar to geom_jitter(). List them and briefly describe what each one does.

ggbeeswarm extends ggplot2 with violin/beeswarm plots.
This package allows plotting of several groups of one dimensional data
as a violin point/beeswarm plot by arranging data points to resemble
the underlying distribution.

You can use geom_quasirandom function to show the violin/beeswarm plots.
geom_quasirandom offsets the points to decrease overplotting.

geom_beeswarm creates offsets based on the number of data points at
that level.

```{r}
diamonds %>%
  ggplot(aes(cut, price)) +
  geom_quasirandom(alpha = 1/10)
```
Just by looking at the transparency of the Fair violin, we can see that
there are fewer points with a Fair cut.
```{r}
diamonds %>%
  group_by(cut) %>%
  summarise(
    num_values = n()
  )
```
For some reason, with the 50,000 points in the diamonds dataset,
the beeswarm plot takes more than a minute to plot. I stopped it.
geom_violin finishes with 1 second.
```{r}
ggplot(data = diamonds, mapping = aes(x = cut, y = price)) +
  geom_violin()
```

## Two categorical variables
To visualize covariation between two categorical variables:
  * If the categorical variables are ordered:
    - use geom_count. It will display the count as a smaller or bigger
      shape at the intersection of each of the values of the two
      variables
    - use count function with dplyr on the two variables,
      then plot and use geom_time(mapping = aes(fill = n))
  * If the categorical variables are unordered:
    - use seriation package to reorder the rows/columns and plot
      them simultaneously
    - for larger plots, try d3heatmap or heatmaply packages, which
      create interactive plots
```{r}
ggplot(data = diamonds) +
  geom_count(mapping = aes(x = cut, y = color))
```
If the count function takes as input the cut and color of diamonds,
the result is a table with cut as rows, and color and the 
number of points in that cut+color category as n.
```{r}
diamonds %>%
  count(cut, color)
```

```{r}
diamonds %>%
  count(cut, color) %>%
  ggplot(mapping = aes(cut, color)) +
  geom_tile(mapping = aes(fill = n))
```

1. How could you rescale the count dataset above to more clearly show the distribution of cut within colour, or colour within cut?

Since the counts are in the low hundreds for Fair cut, and in the
thousands for most of the other cuts, we can use a log base 2 scale
on the count:
```{r}
diamonds %>%
  count(cut, color) %>%
  mutate(log2n = log(n)) %>%
  ggplot(aes(cut, color)) +
  geom_tile(aes(fill = log2n))
```

2. Use geom_tile() together with dplyr to explore how average flight delays vary by destination and month of year. What makes the plot difficult to read? How could you improve it?
```{r}
flights %>%
  group_by(dest, month) %>%
  mutate(avg_arr_delay = mean(arr_delay)) %>%
  ggplot(aes(dest, month)) +
  geom_tile(aes(fill = avg_arr_delay)) +
  coord_flip()
```
There are too many destinations. If we bin them by distance, we will
get some better plot. Still, if the destination is in the northwest,
it has more of a chance of delays due to snow. There are lat/long/altitude
values for each destination in the airports dataset, and we could use
those to decide if the destination is northeast, south, etc., but we don't know how to join datasets yet, so let's just do it by distance and see
what we get.
```{r}
flights %>%
  mutate(log2_distance = round(log2(distance))) %>%
  group_by(log2_distance, month) %>%
  mutate(avg_arr_delay = mean(arr_delay)) %>%
  ggplot(aes(x = log2_distance, y = dest)) +
  geom_tile(aes(fill = avg_arr_delay))
```
Still, the destinations are not readable at all. Also, we cannot
see much difference in the gray scale values to see where it is
on the legend.

3. Why is it slightly better to use aes(x = color, y = cut) rather than aes(x = cut, y = color) in the example above?

Our displays are wider than taller. So using the x scale for a
categorical variable with more categories makes sense. The y scale
is given to the less caregories variable.

7.5.3 Two continuous variables

For the diamonds dataset, a carat vs price plot can have overplotted
points. We use alpha to control it, but this may not be enough for
really large datasets.

geom_bin2d and geom_hex create a grid from two continuous variables,
and plot the number of points at each intersection as a color.
geom_bin2d plots squares, geom_hex plots hexagons.
Install the hexbin package for geom_hex.

```{r}
ggplot(data = smaller) +
  geom_bin2d(mapping = aes(x = carat, y = price))
```
```{r}
ggplot(data = smaller) +
  geom_hex(mapping = aes(x = carat, y = price))
```
Another idea is to bin one variable and use boxplot, barplot to plot
the binned variable on the x axis and the continuous variable on the y.
```{r}
ggplot(data = smaller, mapping = aes(x = carat, y = price)) +
  geom_boxplot(mapping = aes(group = cut_width(carat, 0.1)))
```
cut_width divides the variable into bins of width sizes.

In normal boxplots, you cannot see the variation in the number of points
in each bin. To see that, use varwidth = TRUE. This will change the width
of the bar proportional to the number of points in the bin.

```{r}
ggplot(data = smaller, mapping = aes(x = carat, y = price)) +
  geom_boxplot(mapping = aes(group = cut_width(carat, 0.1)),
               varwidth = TRUE)
```
This may cause you not to see some box widths.

You can also use cut_number instead of cut_width. This displays the same
number of points in each bin.
```{r}
ggplot(data = smaller, mapping = aes(x = carat, y = price)) +
  geom_boxplot(mapping = aes(group = cut_number(carat, 20)))
```
### 7.5.3.1 Exercises

1. Instead of summarising the conditional distribution with a boxplot, you could use a frequency polygon. What do you need to consider when using cut_width() vs cut_number()? How does that impact a visualisation of the 2d distribution of carat and price?

When using cut_width, you need to consider the range. You can take the
full range and divide it into the number of polygons you want, and
make that your width.

When using cut_number, it is the number of polygons you want.

In either case, too many polygons will not be easy to see.

```{r}
ggplot(data = smaller, mapping = aes(x = price)) +
  geom_freqpoly(mapping = aes(color = cut_width(carat, 0.5)),
                binwidth = 500) # binwidth for the price
```
```{r}
ggplot(data = smaller, mapping = aes(x = price)) +
  geom_freqpoly(mapping = aes(color = cut_number(carat, 5)),
                binwidth = 500)
```

2. Visualise the distribution of carat, partitioned by price.
```{r}
ggplot(smaller, aes(price, carat)) +
  geom_boxplot(aes(group = cut_width(price, 500)),
               varwidth = TRUE)
```
```{r}
ggplot(smaller, aes(price, carat)) +
  geom_boxplot(aes(group = cut_number(price, 20)))
```
In this plot, the width of the box is proportional to the number of
diamonds present at those price points and carats.

3. How does the price distribution of very large diamonds compare to small diamonds? Is it as you expect, or does it surprise you?

The price distribution of very large diamonds is much wider than that of
the very small diamonds. I'm not surprised since the very small diamonds
are used in industrial machinery, so market forces determine their price.
This means competition causes prices to be within a small range.
For large diamonds, individuals determine the price. Mainly individuals
with a lot of free cash to spend. So impulse buying, or buying to
impress a lady will create a large range in the price.

4. Combine two of the techniques you’ve learned to visualise the combined distribution of cut, carat, and price.

```{r}
diamonds %>%
  mutate(price_bin = cut_number(price, 10)) %>%
  ggplot(aes(price_bin, carat)) +
  geom_boxplot(aes(fill = cut),
               position = position_dodge(0.9)) +
  scale_fill_manual(values = c("#999999", "#E69F00",
                               "#990000", "#009900", "#000099")) +
  coord_flip()
```
I'm not sure how to rename the price_bin text labels. Maybe we can
use the average value of each bin's left and right boundary values.
If we could, we can plot the graph without coord_flip, which will
give more space to the boxes in it.

5. Two dimensional plots reveal outliers that are not visible in one dimensional plots. For example, some points in the plot below have an unusual combination of x and y values, which makes the points outliers even though their x and y values appear normal when examined separately.
Why is a scatterplot a better display than a binned plot for this case?
```{r}
ggplot(data = diamonds) +
  geom_point(mapping = aes(x = x, y = y)) +
  coord_cartesian(xlim = c(4, 11), ylim = c(4, 11))
```
```{r}
ggplot(data = diamonds) +
  geom_boxplot(aes(x = cut_number(x, 20), y = y)) +
  coord_cartesian(xlim = c(4, 11), ylim = c(4, 11))
```
As you can see, in the boxplot (which is a binned plot), the points
show up close to the IQR box. It is not easy to distinguish which of
them are outliers. In the 2-d scatterplot, the extra second dimension
allows more space to see the outlier as it really is - an outlier.

## Patterns and models

When you spot a pattern, ask yourself:
  * could the relationship be a coincidence?
  * how can you describe the relationship?
  * what is the strength of the relationship?
  * what other variables might affect the relationship?
  * could the relationship be different for subgroups of the data?
  
If you think of variation in a variable decreasing certainity,
covariation in a relationship among variables increases certainity.
Patterns provide a very useful tool for data scientists since they
reveal this covariation.
  * if variables covary, you can use one variable to make predictions
    on the other
  * if two variables have a causal relationship, you can use the value of
    one variable to control the value of the second
    
Models are a tool to extract patterns out of data. In the diamonds dataset
price, carat, and cut are related. We can remove the very strong
relationship between price and carat by fitting a model to them.
When we compute the residuals, they will tell us how the price changes
with the other variables:

```{r}
mod <- lm(log(price) ~ log(carat), data = diamonds)

diamonds2 <- diamonds %>%
  add_residuals(mod) %>% # add a column 'resid' to the diamonds dataset
  mutate(resid = exp(resid))

diamonds2 %>%
  ggplot(aes(carat, resid)) +
  geom_point()
```
These are the residual values after applying the carat vs. price model.
We can now look at the relationship between cut and the residuals.
```{r}
diamonds2 %>%
  ggplot(mapping = aes(x = cut, y = resid)) +
  geom_boxplot()
```

