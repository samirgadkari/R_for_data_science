---
title: "Ch_24_Model_building"
author: "Samir Gadkari"
date: "2/14/2021"
output: html_document
---

```{r}
library(tidyverse)
library(modelr)
options(na.action = na.warn)

library(nycflights13)
library(lubridate)
```

We will:

  * find a pattern with visualizations.
  * Make the pattern concrete with a model.
  * Then repeat this process using the residuals
  
This allows your implicit knowledge in your head to become explicit 
models which can be reused by others.

Another method is to use the predictive power of models to find one
that matches best. This will get you a good pattern match, but you
won't know why. You cannot then make decisions from the model.

For most models, you will probably use the approach in this chapter
combined with the predictive model approach in the last paragraph.

If your model is not working, throw it away and start with a fresh approach.
If your model is good enough, maybe you're done. If you tweak it to
perfection, it will not fit the test data well.

## 24.2 Why are low quality diamonds more expensive?

```{r}
ggplot(diamonds, aes(cut, price)) + geom_boxplot()
ggplot(diamonds, aes(color, price)) + geom_boxplot()
ggplot(diamonds, aes(clarity, price)) + geom_boxplot()
```
x-axis values in the cut and clarity plots above go from worse on 
the left to best on the right. For color, the plot goes from worse
on the right to best on the left.

### 24.2.1 Price and carat

Lower-quality diamonds tend to be larger in size (carat), which 
makes their price higher.
```{r}
ggplot(diamonds, aes(carat, price)) +
  geom_hex(bins = 50)
```

We will fit a model to remove the effect of carat. First, we will
make our dataset easier to work with by:

  1. Filter out diamonds > 2.5 carats. This gives us 99.7% of all
     diamonds in the dataset
  2. Log-transform the carat and price variables. This makes the
     pattern linear, and linear patterns are easier to work with
```{r}
diamonds2 <- diamonds %>%
  filter(carat <= 2.5) %>%
  mutate(lprice = log2(price), lcarat = log2(carat))

ggplot(diamonds2, aes(lcarat, lprice)) +
  geom_hex(bins = 50)
```

Let's fit a model to the pattern:
```{r}
mod_diamond <- lm(lprice ~ lcarat, data = diamonds2)
```

```{r}
grid <- diamonds2 %>% # start with diamonds2 so we limit to
                      # carat <= 2.5
  data_grid(carat = seq_range(carat, 20)) %>%
  mutate(lcarat = log2(carat)) %>% # we do this even when diamonds2
                                   # has this data, because diamonds2
                                   # data is over the carats from the
                                   # diamonds dataset. We have just
                                   # created carat = seq_range() which
                                   # samples evenly across carats.
                                   # So these sample values are
                                   # different from diamonds2 lcarat.
  add_predictions(mod_diamond, "lprice") %>%
  mutate(price = 2 ^ lprice)

ggplot(diamonds2, aes(carat, price)) +
  geom_hex(bins = 50) +
  geom_line(data = grid, color = "red", size = 1)
```

Now let's look at the residuals:
```{r}
diamonds2 <- diamonds2 %>%
  add_residuals(mod_diamond, "lresid")

ggplot(diamonds2, aes(lcarat, lresid)) +
  geom_hex(bins = 50)
```

Now we can re-do our original plots using the residuals instead of
the price:
```{r}
ggplot(diamonds2, aes(cut, lresid)) + geom_boxplot()
ggplot(diamonds2, aes(color, lresid)) + geom_boxplot()
ggplot(diamonds2, aes(clarity, lresid)) + geom_boxplot()
```

Now we see what we expect - the better diamonds need a better price.
Since our residuals are in log2, a -1 residual means the price is
1/2 of our model's expected price. A residual of 1 means the price is
2 times our model's expected price.

### 24.2.2 A more complicated model

We could move the effects we have observed into the model to make them
more explicit, and add other variables:
```{r}
mod_diamond2 <- 
  lm(lprice ~ lcarat + color + cut + clarity, # Notice, we're using
                                              # lcarat to get lprice.
                    # This is how we build the model from previous
                    # knowledge.
     data = diamonds2)
```
Our 4 predictors will make it difficult to visualize. Fortunately,
they're independent, so we can plot them separately. To make the
process easier, we will use .model parameter of data.grid. When it is
added to data_grid, any predictors needed for the model that are not
present are filled in with typical values. Typical values are:

  * median for numeric and ordered factors
  * most frequent value for factors, characters, and logicals
  * It returns all values when there is a tie.
  * NA values are dropped silently.
```{r}
grid <- diamonds2 %>%
  data_grid(cut, .model = mod_diamond2) %>%
  add_predictions(mod_diamond2)
grid
```
```{r}
ggplot(grid, aes(cut, pred)) +
  geom_point()
```

```{r}
diamonds2 <- diamonds2 %>%
  add_residuals(mod_diamond2, "lresid2")

ggplot(diamonds2, aes(lcarat, lresid2)) +
  geom_hex(bins = 50)
```

Since a residual of 2 indicates a diamond 2^2 or 4 x the expected
price. Let's look at unusual values individually:
```{r}
diamonds2 %>%
  filter(abs(lresid2) > 1) %>%
  add_predictions(mod_diamond2) %>%
  mutate(pred = round(2 ^ pred)) %>%
  select(price, pred, carat:table, x:z) %>%
  arrange(price)
```

We don't see anything here, but it is good to check. The difference
could be an opportunity to buy a diamond cheaper than expected.
The difference is usually due to an error in the data.

### 24.2.3 Exercises

1. In the plot of lcarat vs. lprice, there are some bright vertical strips. What do they represent?

They are bright because they represent carats of 1/2, 1, 1.5, 2, etc.
To get these values, use the lcarat value representing the vertical
strip and do: 2^lcaret.
People usually buy known carat sized diamonds, rather than 0.612 ct,
for example. Instead they prefer 1/2 carat so they can say so to their
friends. Also, why would you buy a 0.612 ct, and then say it is 1/2 ct.

2. If log(price) = a_0 + a_1 * log(carat), what does that say about the relationship between price and carat?

Because the relationship is using logs in a linear equation,
it is exponential in nature.

3. Extract the diamonds that have very high and very low residuals. Is there anything unusual about these diamonds? Are they particularly bad or good, or do you think these are pricing errors?

```{r}
ggplot(diamonds2, aes(lresid2)) +
  geom_histogram(bins = 50)
```
From this we see that the diamonds at lresid2 > 1 and lresid2 < -0.75
may have some interest. Let's filter those out:
```{r}
diamonds2_ex <- diamonds2 %>%
  add_predictions(mod_diamond2, var = "lpred2") %>%
  mutate(is_unusual = lresid2 > 1 | lresid2 < -0.75)

diamonds2_ex %>%
  ggplot(aes(carat, price)) +
  geom_point(alpha = 1 / 10) +
  geom_point(data = filter(diamonds2_ex, is_unusual == TRUE),
             color = "red", size = 4, alpha = 1/2)

diamonds2_ex %>%
  ggplot(aes(cut, price)) +
  geom_boxplot(alpha = 1 / 10) +
  geom_point(data = filter(diamonds2_ex, is_unusual == TRUE),
             color = "red", size = 4, alpha = 1/2)

diamonds2_ex %>%
  ggplot(aes(clarity, price)) +
  geom_boxplot(alpha = 1 / 10) +
  geom_point(data = filter(diamonds2_ex, is_unusual == TRUE),
             color = "red", size = 4, alpha = 1/2)

diamonds2_ex %>%
  ggplot(aes(color, price)) +
  geom_boxplot(alpha = 1 / 10) +
  geom_point(data = filter(diamonds2_ex, is_unusual == TRUE),
             color = "red", size = 4, alpha = 1/2)
```
From these plots we can see that:

  * From the carat vs price chart, there are some diamonds which are
    high carats but low price.
  * From the cut vs price chart, we can see that some premium diamonds
    have very low price
  * From the clarity vs price chart, we can see that some I1 clarity
    diamonds, and some SI2 clarity diamonds have prices lower than
    the 25th percentile
  * From the color vs price chart, we can see that some color E
    diamonds have lower than median prices, as do some color R diamonds
    
The next steps would be to see if these diamonds are the same, i.e.
if the color E/F diamonds also have I1/SI2 clarity, premium cut, and
large carat value. If so, they're mispriced.

4. Does the final model, mod_diamond2, do a good job of predicting diamond prices? Would you trust it to tell you how much to spend if you were buying a diamond?

If we can answer the question about the very low resid values,
then we can tell if any of these are mispriced. Since most of the
resid2 histogram shown in exercise 3 is around the 0 value, 
mod_diamond2 seems to do a good job.

## 24.3 What affects the number of daily flights?

```{r}
daily <- flights %>%
  mutate(date = make_date(year, month, day)) %>%
  group_by(date) %>%
  summarise(n = n())

ggplot(daily, aes(date, n)) +
  geom_line()
```
This looks like a weekly pattern.

### 24.3.1 Day of week

Let's look at distribution of flight numbers by day-of-week.
```{r}
daily <- daily %>%
  mutate(wday = wday(date, label = TRUE))

ggplot(daily, aes(wday, n)) +
  geom_boxplot()
```

Most travel is for business, so there are fewer flights on the weekend.
You might leave on Sunday for a Monday morning meeting, but not on
Saturday. This is why the effect is most pronounced on Saturday.

Let's use a model to remove this pattern:
```{r}
mod <- lm(n ~ wday, data = daily)

grid <- daily %>%
  data_grid(wday) %>%
  add_predictions(mod, "n")

ggplot(daily, aes(wday, n)) +
  geom_boxplot() +
  geom_point(data = grid, color = "red", size = 4)
```

Compute and visualize residuals:

```{r}
daily <- daily %>%
  add_residuals(mod)
ggplot(daily, aes(date, resid)) +
  geom_ref_line(h = 0) +
  geom_line()
```
Now that we've removed the strong day-of-week effect, subtler
patterns remain:

  1. The match seems to fail starting in June with large dips.
     Let's draw a plot of 1 line per day of the week:
```{r}
daily %>%
  ggplot(aes(date, resid, color = wday)) +
  geom_ref_line(h = 0) +
  geom_line()
  
```
     
Our model fails to predict Saturday flights. During summer there are
more Saturday flights, and during fall there are fewer.

  2. Here are the days with far fewer flights than expected
```{r}
daily %>%
  filter(resid < -100)
```
  These are related to New years day, July 4th, Thanksgiving, 
  Christmas, and some others.

  3. There seems to be some smoother longer term trend over the
     course of the year. Let's take a look using geom_smooth:
```{r}
daily %>%
  ggplot(aes(date, resid)) +
  geom_ref_line(h = 0) +
  geom_line(color = "grey50") +
  geom_smooth(se = FALSE, span = 0.2)
```
     There are fewer flights during Dec and Jan, and more during the
     summer. We cannot do anything quantitative with this pattern,
     since we have only a single year. But we can use our domain
     knowledge to brainstorm explanations.
     
### 24.3.2 Seasonal saturday effect

Let's focus on Saturday's and see if we can predict the number of
flights:
```{r}
daily %>%
  filter(wday == "Sat") %>%
  ggplot(aes(date, n)) +
  geom_point() +
  geom_line() +
  scale_x_date(NULL, date_breaks = "1 month", date_labels = "%b")
```

This may be caused by leaving for holidays on Saturday during summer.
Flights during fall are less probably because:

  * people have just come from summer vacation
  * people have to go for thanksgiving/christmas holidays

Let's create a term variable for the 3 school terms:
```{r}
term <- function(date) {
  cut(date,
      breaks = ymd(20130101, 20130605, 20130825, 20140101),
      labels = c("spring", "summer", "fall")
  )
}

daily <- daily %>%
  mutate(term = term(date))

daily %>%
  filter(wday == "Sat") %>%
  ggplot(aes(date, n, color = term)) +
  geom_point(alpha = 1 / 3) +
  geom_line() +
  scale_x_date(NULL, date_breaks = "1 month", date_labels = "%b")
```
The dates were manually tweaked to get breaks between terms.
Such techniques are helpful and powerful.

Let's see how the term variable affects the other days of the week:
```{r}
daily %>%
  ggplot(aes(wday, n, color = term)) +
  geom_boxplot()
```
It looks like there is significant difference between terms. So it's
good we tried this approach. Let's look at the residuals:
```{r}
mod1 <- lm(n ~ wday, data = daily)
mod2 <- lm(n ~ wday * term, data = daily)

daily %>%
  gather_residuals(without_term = mod1, with_term = mod2) %>%
  ggplot(aes(date, resid, color = model)) +
  geom_line(alpha = 0.75)
```
This improves our model, but not by much.

We can see the problem by overlaying the predictions over the data:
```{r}
grid <- daily %>%
  data_grid(wday, term) %>%
  add_predictions(mod2, "n")

ggplot(daily, aes(wday, n)) +
  geom_boxplot() +
  geom_point(data = grid, color = "red") +
  facet_wrap(~ term)
```
Our model is using the mean, but we have a lot of outliers. This causes
the mean to be off from the values of most data points. To alleviate
this effect, let's use a model that is robust to outliers: MASS::rlm.
rlm stands for Robust Linear Model.
```{r}
mod3 <- MASS::rlm(n ~ wday * term, data = daily)

with_resid_mod3 <- daily %>%
  add_residuals(mod3, "resid_mod3")

with_resid_mod3 %>%
  ggplot(aes(date, resid_mod3)) +
  # geom_ref_line(h = 0) + # We can use either geom_ref_line(h = 0)
  geom_hline(yintercept = 0, size = 2, color = "white") + # or this
  geom_line()
```
This greatly reduces the impact of outliers and gives a model that
does a good job of removing the day of week pattern.

### 24.3.3 Computed variables

When working with many models and visualizations, it makes sense to
bundle the creation of variables into a function, so you can call it
anytime:

  compute_vars <- function(data) {
    data %>%
      mutate(
        term = term(date),
        wday = wday(date, label = TRUE)
      )
  }

Or, you can put transformations directly into the model formula:

  wday_labeled <- function(x) wday(x, label = TRUE)
  mod3 <- lm(n ~ wday_labeled(date) * term(date), data = daily)
  
The transformations are not useful when working with splines,
since they return multiple columns.

### 24.3.4 Time of year: an alternative approach

An alternative to using our domain knowledge (like using US school
term), when creating a model is to use a more flexible model.
Instead of a linear trend, how about a natural spline:
```{r}
library(splines)
mod <- MASS::rlm(n ~ wday * ns(date, 5),# ns gives natural cubic spline
                 data = daily)          # with knots = 5.

daily %>%
  data_grid(wday, date = seq_range(date, n = 13)) %>%
  add_predictions(mod) %>%
  ggplot(aes(date, pred, color = wday)) +
  geom_line() +
  geom_point()
```

We see a strong pattern in the number of Saturday flights.
But we saw the same pattern in the raw data. This is reassuring.

### 24.3.5 Exercises

1. Use your Google sleuthing skills to brainstorm why there were fewer than expected flights on Jan 20, May 26, and Sep 1. (Hint: they all have the same explanation.) How would these days generalise to another year?

Jan 20 = Sunday
May 26 = Sunday
Sep 1  = Sunday
Since these were weekend days, the number of flights were lower.
Since the weekend days do not occur on the same day of the year,
there is no generalization.

2. What do the three days with high positive residuals represent? How would these days generalise to another year?
```{r}
daily %>% 
  slice_max(n = 3, resid)
```

The positive residual implies the model predicted a low value
compared to the data. This means, there was some reason for the data
during those days to be high.
11/30 and 12/01 represent people returning from Thanksgiving vacation.
12/28 represents people returning from Christmas vacation.

3. Create a new variable that splits the wday variable into terms, but only for Saturdays, i.e. it should have Thurs, Fri, but Sat-summer, Sat-spring, Sat-fall. How does this model compare with the model with every combination of wday and term?
```{r}
term <- function(date) {
  cut(
    date,
    breaks = ymd(20130101, 20130605, 20130825, 20140101),
    labels = c("spring", "summer", "fall")
  )
}

sat_terms <- function(date) {
  case_when(
    wday(date) == 7 ~ str_c(as.character(wday(date, label = TRUE)), 
                            as.character(term(date)),
                            sep = "-"),
    TRUE ~ as.character(wday(date, label = TRUE))
  )
}

# We could not use a MASS::rlm here since either one of these appear
# in the data:
#   * multiple identical rows/columns of the dataset
#   * dataset has a factor where some levels don't have instances
# We should use the data_grid for that.
mod_sat_terms <- lm(n ~ wday * sat_terms(date), 
                    data = with_resid_mod3)

with_resid_mod3 %>%
  mutate(sat_term = sat_terms(date)) %>%
  gather_residuals(mod_sat_terms, .resid = "resid_sat_terms") %>%
  ggplot(aes(date)) +
  geom_line(aes(y = resid_mod3), color = "red") +
  geom_line(aes(y = resid_sat_terms), color = "green")
```
It looks like the wday * sat-term model is not as good as
wday * term. The wday * term model's residuals are closer to 0.

4. Create a new wday variable that combines the day of week, term (for Saturdays), and public holidays. What do the residuals of that model look like?
```{r}
term <- function(date) {
  cut(
    date,
    breaks = ymd(20130101, 20130605, 20130825, 20140101),
    labels = c("spring", "summer", "fall")
  )
}

holidays <- c(ymd(20130101), ymd(20130704), ymd(20131128), 
             ymd(20131225), ymd(20131226))
names(holidays) <- c("New Years", "Independence day", "Thanksgiving",
                     "Christmas Day", "Day after Christmas")
all_of_2013 <- as.list(seq(ymd(20130101), ymd(20131231), by = "day"))
for (i in seq_along(all_of_2013)) {
  date <- all_of_2013[[i]]
  if (date %in% holidays) {
    all_of_2013[i] <- names(holidays)[which(date %in% holidays)]
  } else if (wday(date) == 7) {
    out <- str_c(as.character(wday(date, label = TRUE)), 
                              as.character(term(date)),
                              sep = "-")
    all_of_2013[i] <- out
  } else {
    all_of_2013[i] <- as.character(wday(date, label = TRUE))
  }
}

with_resid_mod3["all_of_2013"] <- as_vector(all_of_2013)

mod_sat_holidays <- MASS::rlm(n ~ all_of_2013, data = with_resid_mod3)

grid <- with_resid_mod3 %>%
  data_grid(all_of_2013) %>%
  add_predictions(mod_sat_holidays)

with_resid_mod3 %>%
  ggplot(aes(all_of_2013)) +
  geom_boxplot(aes(y = n)) +
  geom_point(data = grid, aes(y = pred), 
             color = "red", size = 4) +
  coord_flip()
```

This looks better, because the predictions are within the IQR.
Also, note that only New Years is shown - the other holidays are probably too
many to display on the screen at the same time. We could filter the data
and see them if we like.

Let's see the residuals.

```{r}
with_resid_mod3 %>%
  add_residuals(mod_sat_holidays) %>%
  ggplot(aes(date, resid)) +
  geom_hline(yintercept = 0, size = 2, color = "white") +
  geom_line()
```
This looks like a better model. The sharp spikes are lower in magnitude,
while the rest of the residuals look the same as the wday * sat_terms(date) model.

5. What happens if you fit a day of week effect that varies by month (i.e. n ~ wday * month)? Why is this not very helpful?
```{r}
daily["month"] <- month(daily$date, label = TRUE)
mod_wday_month <- MASS::rlm(n ~ wday * month, data = daily)

daily %>%
  data_grid(wday, month) %>%
  add_predictions(mod_wday_month) %>%
  ggplot(aes(wday, month)) +
  geom_tile(aes(fill = pred))

daily %>%
  add_residuals(mod_wday_month) %>%
  ggplot(aes(date, resid)) +
  geom_ref_line(h = 0) +
  geom_line()
```
This is helpful for a large number of days, except for the holidays.
Since holidays occur in 1-day or 2-day durations, a month predictor is not useful.

6. What would you expect the model n ~ wday + ns(date, 5) to look like? Knowing what you know about the data, why would you expect it to be not particularly effective?

This model will not be very useful because we're smoothing over 5 days. This includes
a weekend day most of the time - only when we're smoothing over M-F will it not
include a weekend day. Since we're also not using wday interaction with the spline,
it will not be very helpful.

7. We hypothesised that people leaving on Sundays are more likely to be business travellers who need to be somewhere on Monday. Explore that hypothesis by seeing how it breaks down based on distance and time: if it’s true, you’d expect to see more Sunday evening flights to places that are far away.
```{r}
flights

# Let's say sunday evening starts from 3pm. Since we're expecting flights going
# far away, travelers may leave early - unless they want to spend more time with
# family. Let's see what the 3pm onwards start time gives us.

make_datetime_100 <- function(year, month, day, time) {
  make_datetime(year, month, day, time %/% 100, time %% 100)
}

flights %>%
  mutate(
    date_time = make_datetime_100(year, month, day, sched_dep_time),
    evening = hour(date_time) > 15
  ) %>%
  filter(wday(date_time, label = TRUE) == "Sun") %>%
  group_by(evening) %>%
  ggplot() +
  geom_hex(aes(x = hour(date_time), y = distance))
```
Looks like Sunday evenings are not busy. Maybe what is happening is that fliers
are leaving Sunday evening, but are taking one short flight to a hub airport,
and continuing from there. We don't know about their other flights, so we cannot
use their actual travel distance.

8. It’s a little frustrating that Sunday and Saturday are on separate ends of the plot. Write a small function to set the levels of the factor so that the week starts on Monday.
```{r}
weekday <- flights %>%
  mutate(
    date_time = make_datetime_100(year, month, day, dep_time),
    wday = wday(date_time, label = TRUE)
  ) %>%
  select(wday, everything())

week_starts_monday <- function(data) {
  fct_relevel(data, "Sun", after = 7) # Moves Sun to after the last level
}
levels(week_starts_monday(weekday$wday))
```

## 24.4 Learning more about models

  * Statistical Modeling: A Fresh Approach by Danny Kaplan
  * An Introduction to Statistical Learning by Gareth James, Daniela Witten, 
    Trevor Hastie, and Robert Tibshirani
  * Elements of Statistical Learning by Trevor Hastie, Robert Tibshirani, 
    and Jerome Friedman
  * Applied Predictive Modeling by Max Kuhn and Kjell Johnson
