---
title: "Ch_5_data_transforms"
author: "Samir Gadkari"
date: "1/5/2021"
output: html_document
---

Hadley Wickham's [R for data science](https://r4ds.had.co.nz/data-visualisation.html), Chapter 5 problems and notes
```{r Load libraries}
library(nycflights13)
library(tidyverse)
```

Since this is a large dataset, only a few rows are printed when you type
flights in the console. To see all the rows, type View(flights) in the console.
This will open the RStudio viewer.

## dplyr basics

Main functions in dplyr that allow you to manipulate the data:

  * filter: pick observations by their name
  * arrange: reorder 
  * select: pick variables by their names
  * mutate: create new variables with functions of existing variables
  * summarise: collapse many values into a summary.
    summarise creates a dataframe. It contains rows for each
    combination of grouping variables.
    If there are no grouping variables, the output will have
    a single row summarising all observations in the input.
These functions used in conjunction with group_by (which changes the function
scope to group level) allow all kinds of data manipulation.

For all these functions:

1. First argument is a dataframe;
2. subsequent arguments describe what to do with the dataframe
3. resulting in a new dataframe

dplyr functions never modify the dataframe.
You have to set it to a variable to capture the updated values.

## Filter rows with filter()
To print out the output of any code, surround it with parentheses.
The line below saves the filter output to jan1 and prints out the
value in jan1.
```{r}
(jan1 <- filter(flights, month == 1, day == 1)) # Multiple arguments are combined 
                                                # with the and operation.
                                                # Use logical operands &, |, !
                                                # to combine using and, or, not.
```
When filtering, if a row produces FALSE, or NA, the row is dropped.
To preserve NA values, you have to ask for them explicitly.
```{r}
(df <- tibble(x = c(1, NA, 3)))
filter(df, x > 1)
(filter(df, is.na(x) | x > 1))
```

### Comparisons

When comparing two floating point numbers, use near()
```{r}
near(sqrt(2) ^ 2, 2)
```

### Logical operations

```{r}
filter(flights, month == 11 | month == 1) # Either month 11 or 1
```

The same can be achieved with the %in% operator
```{r}
filter(flights, month %in% c(11, 1))
```
You can compare two tibbles. The value of each tibble will be compared
individually:
```{r}
x <- filter(flights, month == 11 | month == 1)
x
```

```{r}
x <- filter(flights, month == 11 | month == 1)
y <- filter(flights, month %in% c(11, 1))
all_equal(x, y)
(x == y)[1, ]
```

### Missing values
Any calculation that has a value of NA will produce an NA result.
NA stands for "not available". Even NA == NA will result in NA.
To determine if a value is NA, use is.na().
Note that is.na will find NaN as well as NA.
is.nan will find only NaN values.
```{r}
x <- NA
# y <- 32
is.na(x)
# is.na(y)
```
Some calculations with NA in them will still work.
This is because of shortcuts that the computer uses to do the calculation.
```{r}
(NA ^ 0)     # Anything raised to 0 is 1
(NA | TRUE)  # Anything or-ed with TRUE is TRUE
(FALSE & NA) # Anything an-ded with FALSE is FALSE
(NA * 0)     # Output is NA, because 0 can be a number close to but not 0.
             # So any tiny tiny number times NA should give NA.
```

### 5.2.4 Exercises
Filtering exercises:
```{r}
(filter(flights, sched_arr_time - arr_time >= 120))
(filter(flights, dest == 'HOU' | dest == 'IAH'))
(filter(flights, carrier %in% c('UA', 'AA', 'DL')))

(filter(flights, month %in% 7:9))       # One way to do this, and
(filter(flights, between(month, 9, 9))) # another way to do it.

(filter(flights, (sched_arr_time - arr_time >= 120) & dep_delay < 0))
(filter(flights, (dep_delay > 60) & (sched_arr_time - arr_time < 30)))
(filter(flights, dep_time <= 600))
```

```{r}
# How many flights have a missing dep_time?
(filter(flights, is.na(dep_time))) # There are 8255 rows with NA in dep_time.
(sum(is.na(flights$dep_time)))     # Another way to do this without printing
                                   # the tibble and reading number of rows.

# Find number of missing values per variable
(colSums(is.na(flights)))          # Best way to see number of missing values
                                   # per variable.
```

## Arrange rows with arrange()
Missing values (NA) always show up at the end.
```{r}
(arrange(flights, year, month, day)) # will arrange rows by
                                     #   year, then month, then day
(arrange(flights, desc(dep_delay)))  # will arrange rows by descending dep_delay
```
```{r}
df <- tibble(x = c(5, 2, NA))
(arrange(df, x))
(arrange(df, desc(x)))
(arrange(df, !is.na(x), x))
(arrange(df, !is.na(x), desc(x)))
```
### 5.3.1 Exercises
```{r}
df <- tibble(x = c(5, 2, NA))
(arrange(df, !is.na(x), x))        # Shows NA values at the top, followed by
                                   # ascending x values
(arrange(df, !is.na(x), desc(x)))  # Shows NA values at the top, followed by
                                   # descending x values
(arrange(flights, desc(dep_delay)))  # Find most delayed flights
(arrange(flights, dep_delay))      # Flights that left earliest
(arrange(flights, desc(distance/air_time))) # Highest speed flights
(arrange(flights, desc(distance))) # Furthest travelling flights
(arrange(flights, distance))       # Shortest travelling flights
```

## Select columns with select()
```{r}
select(flights, year, month, day)  # Select given 3 variables
select(flights, year:day)          # Select from year to day - 
                                   # inclusive
select(flights, -(year:day))       # Select everything but year:day
```
Helpful functions to use with select:
* starts_with - matches names that start with the given string
* ends_with   - matches names that end in the given string
* contains    - matches names that contain the given string
* matches     - uses a regex to match variable names
* num_range('x', 1:3) - matches x1, x2, x3 variables

You can try using select to rename variables, but it drops those
variables not explicitly mentioned. Instead, use rename
```{r}
rename(flights, tail_num = tailnum) # Change tailnum -> tail_num
```

Use select in everything() to move select variables to start of the tibble.
```{r}
select(flights, time_hour, air_time, everything())
```

### 5.4.1 Exercises
Brainstorm as many ways as possible to select dep_time, dep_delay, arr_time, and arr_delay from flights.
```{r}
select(flights, dep_time, dep_delay, arr_time, arr_delay)
select(flights, all_of(c('dep_time', 'dep_delay', 
                         'arr_time', 'arr_delay')))
select(flights, dep_time, dep_delay, 
       arr_time, arr_delay, 
       everything())[ , c("dep_time", "dep_delay",
                          "arr_time", "arr_delay")]
```
What happens if you include the name of a variable multiple times in a select() call?
```{r}
select(flights, year, year, month, month)
```
Nothing happens - we only get one instance of each variable.

What does the any_of() function do? Why might it be helpful in conjunction with this vector?
vars <- c("year", "month", "day", "dep_delay", "arr_delay")
```{r}
vars <- c("year", "month", "day", "dep_delay", "arr_delay")
select(flights, -any_of(vars)) # any_of is useful to remove 
                               # variables. If a variable is
                               # missing from the tibble,
                               # it does not throw any errors.

# If any variables inside all_of are missing from the tibble,
# an error is thrown
select(flights, all_of(c('dep_time', 'dep_delay', 
                         'arr_time', 'arr_delay')))
```

Does the result of running the following code surprise you? How do the select helpers deal with case by default? How can you change that default?
```{r}
select(flights, contains('TIME')) # This ignores case.

# This does not ignore case. Since there is no variable with
# uppercase TIME, nothing is selected.
select(flights, contains('TIME', ignore.case = FALSE))
```

## Add new variables with mutate()
Mutate adds new columns to the end. So let's create a small dataset.
```{r}
flights_sml <- select(flights, year:day, ends_with('delay'),
                      distance, air_time)
mutate(flights_sml, 
       gain = dep_delay - arr_delay,
       speed = distance / air_time * 60)

mutate(flights_sml, 
       gain = dep_delay - arr_delay,
       hours = air_time / 60,
       gain_per_hour = gain / hours) # Now you can use new variables
```
To keep only the new variables, use transmute()
```{r}
transmute(flights,
          gain = dep_delay - arr_delay,
          hours = air_time / 60,
          gain_per_hour = gain / hours)
```
### Useful creation functions
Any vectorized function can be used with mutate.
A vectorized function takes and returns a vector with the same
number of values.  These are:

* Arithmetic operators (+, -, *, /, ^). If one part of the expression is a different size than the other, it is extended to the size of the largest variable in the operation.
* Modular arithmetic (%/%, %%).
  - %/% is integer division
  - %% is remainder
```{r}
transmute(flights,
          dep_time,
          hour = dep_time %/% 100,   # integer divide by 100
          minute = dep_time %% 100)  # remainder after div by 100
```
* Log operations (log, log2, log10)

All else being equal, prefer log2 since it is easy to interpret:
  - a difference of 1 on the log scale = doubling,
  - a difference of -1 on the log scale = halving

* Offsets (lead, lag)
```{r}
(x <- 1:10)
lag(x)
lead(x)
```
* Cummulative and rolling aggregates (cumsum, cumprod, cummin, cummax, cummean). To get rolling aggregates, try the RcppRoll package.
```{r}
x
cumsum(x)
cummean(x)
```
* Logical comparisons (<, <=, >, >=, ==, !=)
* Ranking (start with min_rank, then try row_number, dense_rank, percent_rank, cume_dist, ntile).
The default gives the smallest value the smallest rank. Use desc(x) to give largest value the smallest rank.
```{r}
(y <- c(1, 2, 2, NA, 3, 4))
min_rank(y)        # same as rank(ties.method = min)
                   # minimum rank assigned to all tied values
                   # minimum rank assigned to smallest value
min_rank(desc(y))  # same as rank(ties.method = min)
                   # minimum rank assigned to all tied values
                   # maximum rank assigned to smallest value
row_number(y)      # same as rank(ties.method = first)
                   # (y <- c(1, 2, 8, 8, 8, 2, 1)). row_number(y)
                   # gives   1  3  5  6  7  4  2 rankings.
dense_rank(y)      # dense_rank leaves no gaps between ranks.
                   # same values get the same rank.
percent_rank(y) # computed by scaling min rank to 0, max rank to 1
cume_dist(y)    # proportion of all values <= current rank
```

### 5.5.2 Exercises
Currently dep_time and sched_dep_time are convenient to look at, but hard to compute with because they’re not really continuous numbers. Convert them to a more convenient representation of number of minutes since midnight.
```{r}
dep_times <- select(flights, dep_time:sched_dep_time, 
                    arr_time, air_time)
time_to_minutes <- function(t) {
  hour = t %/% 100
  hour * 60 + (t - hour * 100) %% 60
}
dep_times <- mutate(dep_times,
                    dep_time_in_min = time_to_minutes(dep_time),
                    sched_dep_time_in_min = 
                      time_to_minutes(sched_dep_time))
```
Compare air_time with arr_time - dep_time. What do you expect to see? What do you see? What do you need to do to fix it?

air_time should equal arr_time - dep_time. It does not because
the hundredth place of these times are in hours, and the remainder
is in seconds. Instead, now that we've converted 
```{r}
dep_times <- mutate(dep_times,
                    arr_time_in_min = time_to_minutes(arr_time))
```
Now you can see that the arr_time_in_minutes - dep_time_in_minutes
is a little more than the air time. This probably does not include
the sitting on the runway time, taxi to the runway time, etc.

Find the 10 most delayed flights using a ranking function. How do you want to handle ties? Carefully read the documentation for min_rank().
```{r}
# min_rank handles ties by giving the same rank to same-valued
# elements. Thus it skips a rank when ranking the next element.
# If there are ties, there will be skipped numbers.
# Any rank after 10 should be ignored.
flights <- mutate(flights,
                  largest_delays = 
                    min_rank(desc(flights$arr_delay)))
(largest_delays <- filter(flights, largest_delays <= 10))
```

What does 1:3 + 1:10 return? Why?

1:3 is grown to 10 values so it can be added to the 1:10.
The way it is grown is by repeating the same list
over and over until all 10 elements have values in them.
```{r}
(1:3) + (1:10) == c(1, 2, 3, 1, 2, 3, 1, 2, 3, 1) + (1:10)
```

## Grouped summaries with summarise()
When grouping and creating summaries of the groups, it helps to
use the pipe (%>%). It takes the output of the operation on
the left, and passes it as the first argument to the operation
on the right. Since filter, group_by, summarise, mutate, 
and arrange all take a tibble as the first argument, we can use
use %>% to connect our processing together:
```{r}
delays <- flights %>% 
  group_by(dest) %>% 
  summarise(
    count = n(),  # n() gives the current group size. Useful to
                  # ensure you're not drawing conclusions from
                  # very small amounts of data.
    dist = mean(distance, na.rm = TRUE), # na.rm removes NA values
    delay = mean(arr_delay, na.rm = TRUE) # na.rm removes NA values
  ) %>% 
  filter(count > 20, dest != "HNL") # Honolulu is far from other
                                    # airports, so exclude it.
```
```{r}
not_cancelled <- flights %>%
  filter(!is.na(dep_delay), !is.na(arr_delay)) # multiple filter operations are anded
not_cancelled %>%
  group_by(year, month, day) %>%
  summarise(mean = mean(dep_delay))
```

Let's look at delays based on a planes' tailnum.
```{r}
delays <- not_cancelled %>%
  group_by(tailnum) %>%
  summarise(
    delay = mean(arr_delay),
    n = n()
  )
ggplot(delays, mapping = aes(x = delay)) +
  geom_freqpoly(binwidth = 10)
```
There are a few planes with delays of 300 minutes = 5 hours.
Let's draw a scatterplot to see if this conclusion can be made,
or if there are nuances.
```{r}
ggplot(delays, mapping = aes(x = n, y = delay)) +
  geom_point(alpha = 1/10)
```
This is a very characteristic plot of mean and group size. You will see
that the variation in the variable decreases as group size increases.
In this case, the more the number of flights, the less the variation.
If you filter out groups with the smallest number of observations,
you will see more of the pattern among the largest amount of data.
```{r}
delays %>%
  filter(n >= 25) %>%
  ggplot(mapping = aes(x = n, y = delay)) +
    geom_point(alpha = 1/10)
```

### Baseball dataset
Let's find the average performance of batters (batting average vs at bat).
at bat is the number of times they get to hit the ball.
```{r}
batting <- as_tibble(Lahman::Batting)

batters <- batting %>%
  group_by(playerID) %>%
  summarise(
    ba = sum(H, na.rm = TRUE) / sum(AB, na.rm = TRUE),
    ab = sum(AB, na.rm = TRUE)
  )

batters %>%
  filter(ab > 100) %>%
  ggplot(mapping = aes(x = ab, y = ba)) +
    geom_point() +
    geom_smooth(se = FALSE)
```
As before, the variation in our aggregate decreases as we get more data points.
There is also a positive correlation between ab and ba. 
This is because the team will pick the best players to be at bat.

If you naively sort on desc(ba), you will see that people with the best batting
averages are lucky, not skilled (look at their at bat).
```{r}
batters %>%
  arrange(desc(ba))
```

### Useful summary functions
* Measures of location
  - mean
  - median
```{r}
not_cancelled %>%
  group_by(year, month, day) %>%
  summarise(
    avg_delay1 = mean(arr_delay),
    avg_delay2 = mean(arr_delay[arr_delay > 0]) # avg +ve delay
  )
```

* Measures of spread
  - sd 
  - IQR
  - mad  (median absolute deviation - useful because it is more resilient
    to outliers)
```{r}
not_cancelled %>%
  group_by(dest) %>%
  summarise(distance_sd = sd(distance)) %>%
  arrange(desc(distance_sd))
```
* Measures of rank
  - min
  - quantile - quantile(x, 0.25) gives the 25% quantile
  - max
```{r}
not_cancelled %>%
  group_by(year, month, day) %>%
  summarise(
    first = min(dep_time),
    last = max(dep_time)
  )
```

* Measures of position
  - first - same as x[1]
  - nth   - usage: nth(x, 2), same as x[2]
  - last  - same as x[length(x)]
These work the same as subscripts, but
you can specify a default value if none is found.
```{r}
not_cancelled %>%
  group_by(year, month, day) %>%
  summarise(
    first_dep = first(dep_time),
    last_dep = last(dep_time)
  )
```
These functions are similar to filtering on rank,
except filtering gives you all values in each group,
not just the first and last.
```{r}
not_cancelled %>%
  group_by(year, month, day) %>%           # group by year, month, day
  mutate(r = min_rank(desc(dep_time))) %>% # rank by dep_time
  filter(r %in% range(r))  # range(r) produces min(r) and max(r).
                           # filter keeps only the min/max rank,
                           # and removes all other rows in each group.
```

* Counts
  - When summarising, use sum(!is.na(x)) to count non-missing values
  - When summarizing, use n_distinct(x) to count distinct values
  - You can also use count(x) to count number of values
    in each distinct value of x. ex. count(dest) counts
    the number of times each dest occurs in the dataset.
    count(x, wt = y) gives the sum(y) for each value of x
```{r}
not_cancelled %>%
  group_by(dest) %>%
  summarise(carriers = n_distinct(carrier)) %>%
  arrange(desc(carriers))
```

```{r}
not_cancelled %>%
  count(tailnum)
```
```{r}
not_cancelled %>%
  count(tailnum, wt = distance) # group_by(tailnum) %>%
                                #   sum(distance).
                                # Gives total distance
                                # for each tailnum
```
* Counts and proportions of logical values
  - sum(x > 10) - x > 10 creates a vector of TRUE/FALSE values,
    and sum converts TRUE to 1 and FALSE to 0, thus telling you
    how many values match x > 10
  - mean(x > 10) - same as above, except mean produces a
    proportion of values that match x > 10
```{r}
not_cancelled %>%
  group_by(year, month, day) %>%
  summarise(n_early = sum(dep_time < 500)) # number of early
                                           # flights per day
```
What proportion of flights are delayed more than an hour?
```{r}
not_cancelled %>%
  group_by(year, month, day) %>%
  summarise(hour_prop = mean(arr_delay > 60))
```

### Grouping by multiple variables
When you groupby multiple variables, it's easy to progressively
roll up a dataset.
```{r}
(daily <- group_by(flights, year, month, day))
(per_day <- summarise(daily, flights = n())) # n() gives group size
(per_month <- summarise(per_day, 
                        flights = sum(flights))) # sum(flights),
                                                 # not just n()
(per_year <- summarize(per_month, flights = sum(flights)))
```

### Ungrouping with ungroup()
```{r}
daily %>% ungroup() # Removes grouping and gives
                    # you back the entire dataframe.

daily %>% ungroup() %>% summarise(flights = n()) # All flights
```

### 5.6.7 Exercises

Brainstorm at least 5 different ways to assess the typical delay characteristics of a group of flights. Consider the following scenarios:

* A flight is 15 minutes early 50% of the time, and 15 minutes late 50% of the time.
* A flight is always 10 minutes late.
* A flight is 30 minutes early 50% of the time, and 30 minutes late 50% of the time.
* 99% of the time a flight is on time. 1% of the time it’s 2 hours late.

Which is more important: arrival delay or departure delay?
```{r}
# We're only going to consider arrival delay.
# This is looking at the customer's perspective.
# If we were looking at the airline's perspective,
# taking up a gate for the plane at the airport for a long time
# would be an issue, since that gate may be used for other
# flights to disembark passengers. In that case
# departure delay would be critical too.
# From the airlines perspective arrival delay is also
# critical since they don't want to lose passengers,
# and speeding up in flight to get there faster when you
# are late to depart loses fuel (due to fuel efficiency).

# Histogram of delays.
# Here we remove NAs and 0 values so our log2()
# function will not generate errors.
not_cancelled %>%
  filter(!is.na(arr_delay) & arr_delay > 0) %>%
  ggplot(aes(x = log2(arr_delay))) +
  geom_histogram(na.rm = TRUE)
```
Every 1 mark on the x-axis is double the previous mark.
A value of 5 is 2^4 times a value of 1.
So we have around 5000 flights that arrived on time,
10,000 flights that arrived around 2 minutes late (2^1).
The median is probably 5 (i.e. 2^5 = 32 minutes late).
The worst-case is 10 (i.e 2^10 = 1024 minutes or 17 hours late).

```{r}
not_cancelled %>% 
  filter(!is.na(arr_delay)) %>%
  ggplot(aes(x = arr_delay, y = distance)) +
  geom_point(alpha = 1/10)
```
We can see that the longer-duration flights don't have as much delay
as the shorter-duration flights. This is probably because they can
make up that time in-flight.
Also, there are very few flights delayed above 500 minutes (8.3 hours).
I'm guessing it would be frustrating to have a flight delayed more than
a couple hours. If you have a connecting flight, maybe even that is too much.
Let's see how many flights are delayed between 2 and 4 hours.
```{r}
not_cancelled %>%
  filter(!is.na(arr_delay), arr_delay %in% 120:240) %>%
  ggplot(aes(x = arr_delay, y = distance)) +
  geom_point(alpha = 1/10)
```
Now this is a very interesting graph. The horizontal lines are because
there are many flights going to similar distances.
We do see more of a cluster of points towards the bottom left.
This means most flights arrive with less than a delay of 150 minutes.
Let's see if that is true using a histogram.
```{r}
not_cancelled %>%
  filter(!is.na(arr_delay), arr_delay %in% 120:240) %>%
  ggplot(aes(x = arr_delay)) +
  geom_histogram()
```
From the figure, there are 500 flights on average for each bin
from 120 to 150. So that equals (150 - 120) * 500 = 15000 flights.
To find how many flights from 150 to 240, we can consider that
triangle and use the formula 0.5 * (240 - 150) * 500 = 22,500 flights.

Come up with another approach that will give you the same output as not_cancelled %>% count(dest) and not_cancelled %>% count(tailnum, wt = distance) (without using count()).

```{r}
not_cancelled %>% count(dest)

not_cancelled %>%
  group_by(dest) %>%
  summarise(count = n())

not_cancelled %>%
  count(tailnum, wt = distance)

not_cancelled %>%
  group_by(tailnum) %>%
  summarise(count = sum(distance))
```

Our definition of cancelled flights (is.na(dep_delay) | is.na(arr_delay) ) is slightly suboptimal. Why? Which is the most important column?

```{r}
(cancelled_flights <- flights %>%
  filter(is.na(dep_delay) | is.na(arr_delay))) %>%
  select(dep_delay, arr_delay)
```
From this, we can just use is.na(arr_delay) instead of both.
If a flight is cancelled, the arr_delay is always NA.

Look at the number of cancelled flights per day. Is there a pattern? Is the proportion of cancelled flights related to the average delay?
```{r}
flights %>%
  group_by(year, month, day) %>%
  summarise(
    num_cancelled = sum(is.na(arr_delay)),
    avg_delay = mean(arr_delay, na.rm = TRUE)
  ) %>%
  ggplot(aes(x = avg_delay, y = num_cancelled)) +
  geom_point(alpha = 1/10)
```
There is a positive correlation between the avg_delay and number of flights cancelled.
There are a couple of points around avg_delay of 7 minutes, and avg_delay of
25 minutes where the number of flights cancelled are large even though the
avg_delay is low. This may be because most of the flights were grounded
due to a snowstorm, and those that took off could land without much delay
since the destination did not have a snowstorm.

Which carrier has the worst delays? Challenge: can you disentangle the effects of bad airports vs. bad carriers? Why/why not? (Hint: think about flights %>% group_by(carrier, dest) %>% summarise(n()))
```{r}
flights %>%
  group_by(carrier) %>%
  summarise(
    max_delay = max(arr_delay, na.rm = TRUE),
    avg_delay = mean(arr_delay, na.rm = TRUE)) %>%
  arrange(desc(max_delay))
```
Hawaiian Airlines has the most delayed flight, but it's average delay is low.
F9 has the largest average delay, followed by FL.
```{r}
carrier_and_dest_avg_delay <- flights %>% 
  group_by(carrier, dest) %>% 
  summarise(
    avg_delay = mean(arr_delay, na.rm = TRUE),
    num_incoming_flights = n()
  )

carrier_and_dest_avg_delay %>%
  ggplot(aes(x = num_incoming_flights, 
             y = avg_delay,
             color = carrier)) +
  geom_point()

carrier_and_dest_avg_delay %>%
  ggplot(aes(x = num_incoming_flights, 
             y = avg_delay,
             color = dest)) +
  geom_point()
```
Looks like average delay is very good for most carriers.
Even where there are a lot of flights coming into a destination,
the average delay is below 20 minutes.
The larger average delays are given the color green, purple, and blue
for the carriers. Now sure which carriers those are, since the colors
are so close. Maybe we need to separate the carriers into 3 groups
of 6 (there are 17 carriers), and plot them separately.
It's even more difficult to discern the destination points.

What does the sort argument to count() do. When might you use it?
Sort will show the largest groups at the top.

count(sort = TRUE) shows the largest groups at the top. You can use this
when you are interested in the largest groups.

## Grouped mutates and filters

Find worst arrival delay flights per day

```{r}
flights_sml %>%
  group_by(year, month, day) %>%
  filter(rank(desc(arr_delay)) < 10)
```

Find popular destinations
```{r}
popular_dest <- flights %>%
  group_by(dest) %>%
  filter(n() > 365)
popular_dest
```

Standardized group metrics:
```{r}
popular_dest %>%
  filter(arr_delay > 0) %>%
  mutate(prop_delay = arr_delay / sum(arr_delay)) %>%
  select(year:day, dest, arr_delay, prop_delay)
```

Window functions work most naturally with grouped mutates and 
grouped filters. Windows functions:
* take all n values as input
* returns all n values as output

There are five main families of window functions. Two families are unrelated to aggregation functions:

* Ranking and ordering functions: row_number(), min_rank(), dense_rank(), cume_dist(), percent_rank(), and ntile(). These functions all take a vector to order by, and return various types of ranks.

* Offsets lead() and lag() allow you to access the previous and next values in a vector, making it easy to compute differences and trends.

The other three families are variations on familiar aggregate functions:

* Cumulative aggregates: cumsum(), cummin(), cummax() (from base R), and cumall(), cumany(), and cummean() (from dplyr).

* Rolling aggregates operate in a fixed width window. You won't find them in base R or in dplyr, but there are many implementations in other packages, such as RcppRoll.

* Recycled aggregates, where an aggregate is repeated to match the length of the input. These are not needed in R because vector recycling automatically recycles aggregates where needed. They are important in SQL, because the presence of an aggregation function usually tells the database to return only one row per group.

### 5.7.1 Exercises
Refer back to the lists of useful mutate and filtering functions. Describe how each operation changes when you combine it with grouping.

With grouping, all these function work separately on each group.
The functions are:
* Arithmetic operators:         + - * / ^
* Modular arithmetic operators: %/% %%
* Logs:                         log log2 log10
* Offsets:                      lead lag
* Cummulative:                  cumsum cumprod cummin cummax cummean
* Ranking:                      min_rank row_number dense_rank
                                percent_rank cume_dist ntile

Which plane (tailnum) has the worst on-time record?

Should we use:
* mean(arr_delay) or
* max(arr_delay)?

Since we're looking for worst, maybe max(arr_delay).
This still means that this plane may be fine with other flights,
but was really bad once.

We can also look at the histograms of the delays for each tailnum.
So how many tailnums are there?
```{r}
not_cancelled %>%
  group_by(tailnum) %>%
  summarise(n = n()) %>%
  nrow()
```

There are 4037 tailnums. Let's not look at histograms of them all.
Instead, we will calculate max(arr_delay) and mean(arr_delay),
and them get a scatterplot of both.

```{r}
max_mean_arr_delays <- not_cancelled %>%
  group_by(tailnum) %>%
  summarise(max_arr_delay = max(arr_delay),
            mean_arr_delay = mean(arr_delay))

max_mean_arr_delays %>%
  ggplot(aes(x = max_arr_delay, y = mean_arr_delay)) +
  geom_point(alpha = 1/10)

# This will show us which flight has the worst max delay
# and mean delay. We're focusing on the flight in the
# upper-right of the graph.
max_mean_arr_delays %>%
  filter(max_arr_delay > 900, mean_arr_delay > 150)

(worst_flight <- not_cancelled %>%
  filter(tailnum == 'N665MQ') %>%
  select(origin, dest, arr_delay, distance))
```
From the graph, we can see that there is a straight line artifact.
Maybe the mean arrival delay of some flights increases as they
encounter a single large delay, and this is the graph.
Should investigate this further.
We can also see that the top-right part of the graph shows
a flight that has a large max_arr_delay as well as a large
mean_arr_delay. We will focus on that as our worst tailnum plane.
In reality, we cannot find the worst flight by tailnum because
pilots change, destinations change, crews change, for each tailnum.
There is no reason why a certain tailnum is bad this time, and
continues to be bad all the time.

From the table above we can see that this flight got a bad grade
because of one flight to CVG (Cincinnati). Just bad luck.

What time of day should you fly if you want to avoid delays as much as possible?
```{r}
not_cancelled %>%
  ggplot(aes(x = dep_time, y = arr_delay)) +
  geom_point(alpha = 1/ 10)
```
Most of the delays for the early morning flights (from 4am) are the best.
The earlier the better.

For each destination, compute the total minutes of delay. For each flight, compute the proportion of the total delay for its destination.
```{r}
not_cancelled %>%
  group_by(dest) %>%
  summarise(total_dest_delay = sum(arr_delay),
            prop_dest_delay = arr_delay / total_dest_delay)
```

Delays are typically temporally correlated: even once the problem that caused the initial delay has been resolved, later flights are delayed to allow earlier flights to leave. Using lag(), explore how the delay of a flight is related to the delay of the immediately preceding flight.

These are all NY city flights. Any delay associated with any airport
in the NY metro area will be associated with all airports. ex.
snowstorm delays, so we will not check each airport separately.

```{r}
(lags <- not_cancelled %>%
  select(year, month, day, dep_time, dep_delay))

(lags <- lags %>%
  arrange(year, month, day, dep_time) %>%    
  mutate(lag = dep_delay - lag(dep_delay)))

# Let's check the lags around new years
lags %>%
  group_by(year, month, day) %>%
  ggplot(aes(x = dep_time, y = lag)) +
  geom_point(alpha = 1/10, na.rm = TRUE)
```
You can see how the variation increases from 500 through 1300, 
and is then constant until it starts going down around 100.
The best time to travel seems to be between 3am and 5am.

Look at each destination. Can you find flights that are suspiciously fast? (i.e. flights that represent a potential data entry error). Compute the air time of a flight relative to the shortest flight to that destination. Which flights were most delayed in the air?
```{r}
calc_speed <- function(arr_time, dep_time, distance) {
  arr_time = time_to_minutes(arr_time)
  dep_time = time_to_minutes(dep_time)
  distance / (arr_time - dep_time) * 60
}

(fastest_flights <- not_cancelled %>%
  select(dest, arr_time, dep_time, distance) %>%
  group_by(dest) %>%
  mutate(speed = calc_speed(arr_time, dep_time, distance)))

(fastest_flights %>%
  ggplot(aes(x = distance, y = speed)) +
  geom_point(alpha = 1/8))

(error_flights <- fastest_flights %>%
  filter(speed < 0))
```
All of the flights that seem too speedy (speed < 0) are due to the
arrival time being the next day morning while departure time is
evening of the earlier day. So the departure time value is high,
and the arrival time value is low - giving a negative speed.

```{r}
calc_speed <- function(arr_time, dep_time, distance) {
  reversed_time = FALSE
  if (dep_time > arr_time) {
    reversed_time = TRUE
  }
  
  arr_time = time_to_minutes(arr_time)
  dep_time = time_to_minutes(dep_time)
  
  if (reversed_time == TRUE) {
    arr_time = arr_time + dep_time
    dep_time = 0
  }
  
  distance / (arr_time - dep_time) * 60
}

(fastest_flights <- not_cancelled %>%
  select(dest, arr_time, dep_time, distance) %>%
  group_by(dest) %>%
  mutate(speed = calc_speed(arr_time, dep_time, distance)))

(fastest_flights %>%
  ggplot(aes(x = distance, y = speed)) +
  geom_point(alpha = 1/8))

(error_flights <- fastest_flights %>%
  filter(speed < 0))
```

There are still many cases where the speed is negative. This is
probably because they're in a different time zone. Since there is no
variable in flights to change the dep_time or arr_time to the same
time zone, we cannot do anything about this.

Find all destinations that are flown by at least two carriers. Use that information to rank the carriers.

```{r}
(important_dest <- flights %>%
  group_by(dest) %>%
  summarise(num_carriers = n_distinct(carrier)) %>%
  filter(num_carriers >= 2) %>%
  pull(dest))

carrier_n <- flights %>%
  filter(dest %in% important_dest) %>%
  group_by(carrier) %>%
  summarise(n = n())
carrier_n %>%
  summarise(carrier = carrier, 
            rank = rank(n, ties.method = 'min')) %>%
  arrange(desc(rank))
```

For each plane, count the number of flights before the first delay of greater than 1 hour.
```{r}
(lag <- not_cancelled %>%
  group_by(tailnum) %>%
  summarise(lag = arr_delay - lag(arr_delay)))
```
I don't know how to stop the count in each group if lag > 60.