---
title: "Ch_11_Data_import"
author: "Samir Gadkari"
date: "1/18/2021"
output: html_document
---
```{r}
library(tidyverse)
read_path = Sys.getenv('DATASETS')
write_path = paste(read_path, 'output', sep = '/')

full_read_path <- function(filename) {
  paste(read_path, filename, sep = '/')
}

full_write_path <- function(filename) {
  paste(write_path, filename, sep = '/')
}
```

## 11.2 Getting started

  * read_csv reads comma separated files
  * read_csv2 reads semicolon separated files
  * read_tsv reads tab separated files
  * read_delim reads files with any delimeter
  * read_fwf reads fixed-width files
    - fwf_widths or fwf_positions give either the widths or
      positions to read_fwf as the second argument after the
      file handle
  * read_log reads Apache-style log files.
    Also check out webreadr which is built on top of read_log
    and provides many more helpful tools

```{r}
mens_shoe_prices <-
  read_csv(full_read_path('mens_shoe_prices.csv'))
```
You can see how read_csv shows a column specification for the
data it just read.

If there are any problems, you can look at them using the
problems function on the tibble.

To create an example tibble:
```{r}
# First line of data are the column names
read_csv('a, b, c
1, 2, 3
4, 5, 6')
```

There are two cases when reading from a delimited file:
1. A few lines of metadata at the top of the file should be
removed.

You can use:
  * skip = n to skip n lines at the top of the file
  * comment = '#' to drop lines starting with #
```{r}
read_csv('This is a comment
and so is this
x, y, z
1, 2, 3', skip = 2)

read_csv('# this is a comment
# which should be skipped
a, b, c
1, 2, 3', comment = '#')
```

2. The data might not have column names. You have to:
  * Use the read_csv function with col_names = FALSE to
    start reading data from the first line in the file.
    This also provides temporary names for each column (
    X1, X2, ... Xn)
```{r}
read_csv('1, 2, 3\n4, 5, 6', col_names = FALSE)
```
    
  * Specify column names using col_names = c('A', 'B', 'C')
```{r}
read_csv('1, 2, 3\n4, 5, 6', col_names = c('A', 'B', 'C'))
```

To handle NA values, you can specify na = with value or values
that will be replaced with NA:
```{r}
read_csv('1, 2, na\n4, ., 6', col_names = FALSE, 
         na = '.')
read_csv('1, 2, na\n4, ., 6', col_names = FALSE, 
         na = c('na', '.'))
```
To read in more challenging files, look at readr documentation.

## 11.2.1 Compared to base R
Why do we use readr package's read_csv 
instead of base R's read.csv?

  * read_csv is approximately 10x faster than base R's read.csv.
  
    data.table::fread() is fastest, but does not fit well
    with tidyverse
  * readr functions
    + produce tibbles
    + don't convert character vectors to factors
    + don't use row names (like index in pandas).
    
      When you convert a data.frame to a tibble, it will
      have row names. These functions help you process the
      row names of a data.frame
      - has_rownames(df)
      - remove_rownames(df)
      - rownames_to_column(df, var = 'rowname')
      - rowid_to_column(df, var = 'rowid')
      
        adds a column at the start of a dataframe with
        ascending sequential numbers in it
      - column_to_rownames(df, var = 'rowname')
    + don't munge column names
  * they're more reproducible. 
    
    Base R uses some environment variables and behavior
    from your operating system. This means code that works 
    on your computer may not work on someone else's computer.

## 11.2.2 Exercises

1. What function would you use to read a file where fields were separated with “|”?

read_delim

2. Apart from file, skip, and comment, what other arguments do read_csv() and read_tsv() have in common?

All arguments are the same between the two. These are the
other arguments:
col_names, col_types, locale, na, progress, skip_empty_rows
Other arguments with explanations:
guess_max: max number of records used to guess column types
n_max:     max number of records to read
quote:     single character used to quote strings
quoted_na: should missing values inside quotes be treated
           as missing values (default) or strings
trim_ws:   should leading/trailing whitespace be trimmed?

3. What are the most important arguments to read_fwf()?

file, col_types, na, trim_ws, skip, skip_empty_rows
Other arguments with explanations:
col_positions: column positions created by fwf_widths, 
               fwf_positions, or fwf_empty
               
4. Sometimes strings in a CSV file contain commas. To prevent them from causing problems they need to be surrounded by a quoting character, like " or '. By default, read_csv() assumes that the quoting character will be ". What argument to read_csv() do you need to specify to read the following text into a data frame?

"x,y\n1,'a,b'"
```{r}
read_csv("x,y\n1,'a,b'", quote = "\'")
```

5. Identify what is wrong with each of the following inline CSV files. What happens when you run the code?
```{r}
# creates a 2 x 2 table - does not include 3, 6 since
# there are not enough column names in the top row
read_csv("a,b\n1,2,3\n4,5,6")

# 2 columns specified in the top row, but
# 2 values in first data row, so last column value is NA, and
# 4 values in second data row, so last value ignored.
read_csv("a,b,c\n1,2\n1,2,3,4")

# 2 columns specified in top row, 
# 1 value in second row, so second column has value NA.
# Also since quote is not specified, quotes are dropped,
# and value of 1 <dbl> is used
read_csv("a,b\n\"1")

# 2 columns specified in top row,
# second row could be <dbl>, but
# third row are all characters.
# Since columns need to have the same type,
# all columns are <chr>
read_csv("a,b\n1,2\na,b")

# Should have used read_delim with delim = ';'.
# Top row is combined into one name 'a;b', and
# first data row is combined into one '1;3', so
# the type of the column is character.
read_csv("a;b\n1;3")
```

## 11.3 Parsing a vector

parse_* functions take a character vector and return a more
specialised vector like a logical, integer, or date.
```{r}
str(parse_logical(c('TRUE', 'FALSE', 'TRUE')))
str(parse_integer(c('1', '2', '3')))
str(parse_date(c('2010-01-01', '2020-01-01')))
```
parse_* functions have na argument which converts those strings
into NA values:
```{r}
parse_integer(c('1', '123', '.', '256'), na = '.')
```

If parsing fails, you get a warning, and the failures will be
missing from the output:
```{r}
x <- parse_integer(c('123', '456', 'abc', '45.26'))
```

If there are many failures, you will need to use problems(df)
to get the complete set:
```{r}
problems(x) # returns a tibble
```

Eight important parsers:

  * parse_logical, parse_integer
  * Numeric parsers
  
    parse_double:  strict numeric parser
    
    parse_number:  flexible numeric parser
    
    These are more complicated because numbers are written
    differently in different countries.
    
  * Character parsers
  
    parse_character: encodings make this complicated
    
  * Factor parsers
  
    parse_factor: creates factors to represent categories
    
  * Date and time parsers
  
    These allow you to parse various types of dates and times
    
    parse_datetime 
    
    parse_date
    
    parse_time

The following sections describe these parsers in detail.

## 11.3.1 Numbers

This is tricky because:

  * In some countries the integer and fractional parts are
    separated by , instead of by . Use locale to fix this:
    
```{r}
parse_number('1.23')
parse_number('1,23', locale = locale(decimal_mark = ','))
```
readr's locale defaults to US, since R is US-centric.  
  
  * Numbers are often surrounded by other characters like
    $ or %. parse_number ignores extra characters before and
    after the numeric characters:
    
```{r}
parse_number('$100')
parse_number('87%')
parse_number('It cost $123.48')
```

    
  * Numbers often contain grouping characters like , 
    ex: 1,000,000. parse_number ignores grouping characters.
    You can use locale if the grouping character is different
    from the default ,:
```{r}
parse_number('$1,234,567')

# In Europe, grouping mark of , and decimal mark of .
# are used. Here the output has this number 
# rounded up
parse_number('123.456.789,89', 
             locale = locale(grouping_mark = '.',
                             decimal_mark = ','))

# The swiss use ' as a grouping mark
parse_number("123'456'789",
             locale = locale(grouping_mark = "'"))
```
    
## 11.3.2 Strings

    